---
title: 'Class 9: Bayesian Hierarchical Models'
author: Andrew Parnell\newline \texttt{andrew.parnell@mu.ie} \newline \vspace{1cm}
  \newline \includegraphics[width=5cm]{MU_logo.jpg}
output:
  beamer_presentation:
    includes:
      in_header: header.tex
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dev = 'pdf')
par(mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.01,las=1)
library(rstanarm)
library(bayesplot)
```

## Learning outcomes:

- Start fitting hierarchical GLMs in `rstanarm`
- Know some of the different versions of Hierarchical GLMs
- Be able to expand and summarise fitted models

## From LMs to HGLMs

- The Bayesian analogue of a mixed model is a _hierarchical model_. 
- It's called a hierarchical model because the prior distributions come in layers, they depend on other parameters
- Within this framework, we can borrow the ideas from the previous class to create hierarchical GLMs
- We will go through four examples: binomial-logit, Poisson, robust regression, and ordinal regression 

## Example 1: binomial-logit

- Earlier we met the Binomial-logit model for binary data:
$$y_i \sim Bin(1, p_i), logit(p_i) = \alpha + \beta (x_i - \bar{x})$$
Here $logit(p_i)$ is the link function equal to $\log \left( \frac{p_i}{1-p_i} \right)$ and transforms the bounded probabilities into an unbounded space

- If we have non-binary data we just change the likelihood:
$$y_i \sim Bin(N_i, p_i), logit(p_i) = \alpha + \beta (x_i - \bar{x})$$

- In a hierarchical version of this model, we vary the _latent parameters_ $\alpha$ and $\beta$ and give them prior distributions

## The swiss willow tit data

\tiny
```{r}
swt = read.csv('../data/swt.csv')
head(swt)
```

## A hierarchical model

\small
- Suppose we want to fit a model on the sum $y_i =$ `rep.1 + rep.2 + rep.3`:
$$y_i \sim Bin(N_i, p_i), logit(p_i) = \alpha_{\mbox{altitude}_i} + \beta_{\mbox{altitude}_i} (x_i- \bar{x})$$
where $x_i$ is the percentage of forest cover

- What prior distributions should we use for $\alpha$ and $\beta$?

- Useful side note: A value of 10 on the logit scale leads to a probability of about 1, and a value of -10 leads to a probability of about 0 (you can test this by typing `inv.logit(10)`) so I wouldn't expect the value of $logit(p_i)$ to ever get much bigger than 10 or smaller than -10

- I have no idea whether we are more likely to find these birds in high percentage forest or low, so I'm happy to think that $\beta$ might be around zero, and be positive or negative. Forest cover ranges from 0 to 100 so that suggests that $\beta$ is every likely to be bigger than 0.1 or smaller than -0.1. Perhaps $\beta \sim N(0, 0.1^2)$ is a good prior

- It looks to me like the intercept is very unlikely to be outside the range (-10, 10) so perhaps $\alpha \sim N(0, 5^2)$ is appropriate

## `rstanarm` code

```{r, include = FALSE}
sum_fun = function(x) {
  s = ifelse(is.na(x[1]),0,x[1]) + ifelse(is.na(x[2]),0,x[2]) + ifelse(is.na(x[3]),0,x[3])
  N = ifelse(is.na(x[1]),0,1) + ifelse(is.na(x[2]),0,1) + ifelse(is.na(x[3]),0,1)
  return(c(s,N))
}
swt$y = apply(swt[,1:3],1,sum_fun)[1,]
swt$N = apply(swt[,1:3],1,sum_fun)[2,]
```

\tiny
```{r, message = FALSE, warning = FALSE, results = 'hide'}
mod_1 = stan_glmer(cbind(y, N) ~  (forest | alt),
                  data = swt,
                  family = binomial(link = 'logit'),
                  prior = normal(0, 0.1),
                  prior_intercept = normal(0, 5))
```

## Model summary 1

\tiny
```{r}
round(as.data.frame(summary(mod_1)), 2)
```

## Model summary 2

```{r}
plot(mod_1)
```

## Model fit - intercepts

```{r, echo = FALSE, message=FALSE, results = 'hide'}
mcmc_hist(as.data.frame(mod_1), regex_pars = 'b\\[\\(Intercept',
          facet_args = list(nrow = 3))
```

## Model fit - Slopes

```{r, echo = FALSE, message=FALSE, results = 'hide'}
mcmc_hist(as.data.frame(mod_1), regex_pars = 'b\\[forest')
```


## Model fit - posterior predictive check

```{r, fig.height = 5}
y_rep = posterior_predict(mod_1)
y_rep_mean = apply(y_rep, 2, 'mean')
plot(swt$y, y_rep_mean)
abline(a = 0, b = 1, col = 'red')
```

## Model fit - posterior predictive check 2

```{r, echo=FALSE}
pp_check(mod_1)
```

## Type 2: Poisson HGLMs

- For a Poisson distribution there is no upper bound on the number of counts

- We just change the likelihood (to Poisson) and the link function (to $\log$):
$$y_i \sim Po(\lambda_i), \log(\lambda_i) = \alpha + \beta (x_i - \bar{x}))$$

- We can now add our hierarchical layers into $\alpha$ and $\beta$, or...

- Another way we can add an extra layer is by giving $\log(\lambda_i)$ a probability distribution rather than setting it to a value

- This is a way of introducing _over-dispersion_, i.e. saying that the data are more variable than that expected by a standard Poisson distribution with our existing covariates

## An over-dispersed model

- The over-dispersed model looks like:
$$y_i \sim Po(\lambda_i), \log(\lambda_i) \sim N(\alpha + \beta (x_i - \bar{x}), \sigma^2)$$
where $\sigma$ is the over-dispersion parameter

- We now need to estimate prior distributions for $\alpha$, $\beta$, and $\sigma$

- We will use the SWT data again, but pretend that we didn't know that they had gone out $N$ times looking for the birds

## `rstanarm` code for OD Poisson

```{r, message = FALSE, results = 'hide', warning=FALSE, fig.height = 5}
swt$obs <- 1:nrow(swt)
mod_2 = stan_glmer(y ~ forest + (1 | obs),
              family = poisson, data = swt)
mcmc_hist(as.data.frame(mod_2), regex_pars = 'forest')
```

## Posterior predictive check

```{r}
pp_check(mod_2)
```

## Notes about OD Poisson model

- The way to think about OD models is via the data generating process. Draw a DAG and think about how these processes might arise

- We could compare this model to one without over dispersion via the PPC (or if time, cross validation). 

- In general, the parameter values (i.e. the intercepts and slopes) tend to be more uncertain when you add in over dispersion

- Also in the data set is a variable called `dur` which represents how long they spent looking for the birds. This could be added in as an offset via the likelihood

## Type 4: Ordinal data HGLMs

- Often we have a response variable which is ordinal, e.g. disagree, neutral, agree, etc
- There are lots of different (and complicated) ways to model such data
- Perhaps the easiest is to think of it as a hierarchical model with 'cut-points' on a latent linear regression

## An ordinal model example

- Suppose $y_i = \{\mbox{disagree, neutral, agree} \}$ and we make it dependent on a latent continuous variable $z_i$, so that :

$$y_i = \left\{ \begin{array}{ll} \mbox{agree} & \mbox{if } z_i> 0.5 \\
\mbox{neutral} & \mbox{if } -0.5 < z_i \le 0.5 \\
\mbox{disagree} & \mbox{if } z_i \le -0.5 \end{array} \right.$$

- We then give $z_i$ a prior distribution, e.g. $N(\beta_0 + \beta_1 x_i, \sigma^2)$

## Simulating some example data

```{r}
N = 100
alpha = -1
beta = 0.2
sigma = 0.51
set.seed(123)
x = runif(N, 0, 10)
cuts = c(-0.5, 0.5)
z = rnorm(N, alpha + beta * (x - mean(x)), sigma)
y = findInterval(z, cuts)
dat = data.frame(y = as.factor(y),
                 x = x)
```

## Simulated data - plot

```{r}
plot(x, z, col = y + 1)
```


## Fitting in `rstanarm`

```{r, message=FALSE, results = 'hide', warnings = FALSE}
mod_3 <- stan_polr(y ~ x, 
                   data = dat,
                   prior = R2(0.25, 'mean'), 
                   prior_counts = dirichlet(1))
```

## Output

\small
```{r, fig.height = 5}
mcmc_hist(as.data.frame(mod_3))
```

## Summary

- We have now seen a number of different types of hierarchical GLM
- Many of the ideas of hierarchical linear models transfer over, but we can explore richer behaviour with hierarchical GLMs
- These have all used the normal, binomial or Poisson distribution at the top level, and have allowed for over-dispersion, robustness, and ordinal data, to name just three

