---
title: 'Class 1: Introduction to Frequentist and Bayesian Mixed/Hierarchical Modelling'
author: Andrew Parnell \newline \texttt{andrew.parnell@mu.ie}   \newline \vspace{1cm}
  \newline \includegraphics[width=5cm]{MU_logo.jpg}
  \newline \vspace{2cm}
  https://goo.gl/fCH4cU
output:
  beamer_presentation:
    includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dev = 'pdf')
par(mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.01,las=1)
```

## Let's get started

- Tell me who you are, what you are working on, and what you hope to get out of the week
- Timetable for the week
- Prerequisites

## How this course works

- This course lives on GitHub, which means anyone can see the slides, code, etc, and make comments on it
- The timetable html document provides links to all the pdf slides and practicals
- The slides and the practicals are all written in `Rmarkdown` format, which means you can load them up in Rstudio and see how everything was created
- Let me know if you spot mistakes, as these can be easily updated on the GitHub page
- There is a `IFBM.Rproj` R project file from which you should be able to run all the code

## Course format and other details

- Lectures will take place in the morning, practical classes in the afternoon
- Timetable very flexible
- Please ask lots of questions
- Some good books:

    - _lme4: Mixed-effects modeling with R_ by Bates
    - _Data Analysis using Regression and Hierarchical Models_ by Gelman and Hill
    - _Bayesian Data Analysis_ by Gelman et al

## What is a mixed model?

- __A model__ is just a representation/approximation of the real world, here expressed in equations
- __Mixed__ means that the model is built up of _fixed_ and _random_ effects 
- __Fixed effects__ do not vary between groups, 
- __Random effects__ vary between groups such that their variation is controlled and can be removed

## Thinking about mixed models: example 1

```{r, echo = FALSE}
# Feed conversion rate example
fcr = read.csv(file = '../data/fcr.csv')
plot(fcr$food_wt, fcr$weight_gain, 
     xlab = 'food weight (kg)', 
     ylab = 'Weight gain (kg)')
```

## More information:

```{r, echo = FALSE}
sex = fcr$sex
plot(fcr$food_wt[sex=='male'], 
     fcr$weight_gain[sex=='male'], 
     xlab = 'food weight (kg)', 
     ylab = 'Weight gain (kg)',
     xlim = range(fcr$food_wt), 
     ylim = range(fcr$weight_gain), 
     pch = 19, col = 'blue')
points(fcr$food_wt[sex=='female'], 
       fcr$weight_gain[sex=='female'], 
       pch = 19,
       col = 'red')
legend('topleft', legend = c('Males', 'Females'), 
       pch = 19, col = c('blue', 'red'))
```


## Example 2: 8 Schools

We have 8 schools in a region, with a relative performance score (column `score`) compared to the national average and a standard deviation (`sigma`) based on 3 repeated visits

\tiny
```{r, echo = FALSE}
schools = read.csv('../data/schools.csv')
print(schools)
```
\normalsize

- If you had to pick an overall score for this region how would you calculate it?
- If you had to guess the score of a new measurement for school 1 what value would you use?

## Example 3: Earnings data

1192 observations on earnings (in USD) and various measurements about ethnicity, age, height, etc

\tiny
```{r, echo = FALSE}
dat = read.csv('../data/earnings.csv')
head(dat)
```
\normalsize

- Does height affect earnings?
- Are there different rates of change for different groups (e.g. age/ethnic groups)?


## Example 4: Swiss Willow Tit data

3 replicate measurements on whether Swiss Willow Tits were found with covariates on forest cover and elevation
\tiny
```{r, echo=FALSE}
swt = read.csv('../data/swt.csv')
head(swt)
```
\normalsize

- How do the covariates affect the chance of finding the birds?
- Are these effects linear?
- What do we do with the missing data?

## More data sets in the data directory

- The data directory contains a few more data sets which we will play with throughout the week
- The `data_descriptions.txt` file shows what they contain
- If you have some spare time it's worth loading them in, exploring relationships, and fitting some simple models

## Summary

- In mixed models we try to avoid fitting models to separate parts of the data as much as possible

- By fitting models together we __borrow strength__ from the different groups in the data and reduce uncertainty

- (Later in the week) Bayesian models allow us to incorporate all the available information to answer the key question(s) of interest
