---
title: 'Class 8: Bayesian Linear and generalised linear models (GLMs)'
author: Andrew Parnell\newline \texttt{andrew.parnell@mu.ie} \newline \vspace{1cm}
  \newline \includegraphics[width=5cm]{MU_logo.jpg}
output:
  beamer_presentation:
    includes:
      in_header: header.tex
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dev = 'pdf')
par(mar=c(3,3,2,1), mgp=c(2,.7,0), tck=-.01,las=1)
library(rstanarm)
library(boot)
#options(mc.cores = parallel::detectCores())
```

## Learning outcomes

- Understand the basic formulation of a GLM in a Bayesian context
- Understand the code for a GLM in `rstanarm`
- Be able to pick a link function for a given data set
- Know how to check model assumptions for a GLM

## Aside: thinking about the data generating process for a standard LM

If we believe that a linear model is appropriate for our data, there are several ways we could generate data from the model. Here is one way:
```{r}
N = 10
x = 1:N
y = rnorm(N, mean = -2 + 0.4 * x, sd = 1)
```

Here is another:
```{r}
eps = rnorm(N, mean = 0, sd = 1)
y = -2 + 0.4 * x + eps
```

## The data generating process for a logistic regression

\scriptsize
- What if the response variable was binary? Clearly the previous code will not produce binary values
- Instead we could simulate from the binomial distribution:
```{r, warning=FALSE}
y = rbinom(N, size = 1, prob = -2 + 0.4 * x)
```
... but this will produce `NA`s as the `prob` argument needs to be between 0 and 1. We need to transform the values involving the covariate

- A popular way is to use the inverse logit function. Look!
```{r}
-2 + 0.4 * x
exp(-2 + 0.4 * x)/(1 + exp(-2 + 0.4 * x))
```
- In fact you can take any number $a$ from $-\infty$ to $\infty$ and create $\exp(a)/(1+\exp(a))$ and it will always lie between 0 and 1

## Generating binomial data

- Thus a way to generate binary data which allows for covariates is:
```{r}
library(boot)
p = inv.logit(-2 + 0.4 * x)
y = rbinom(N, size = 1, prob = p)
y
```

- The logit function itself is $\log \left( \frac{p}{1-p} \right)$ and will turn the probabilities form the range (0,1) to the range $(-\infty,\infty)$
- Using this type of model is known as _logistic-Binomial_ regression and the logit is known as the _link function_

## Generating other types of data

- Once we have discovered link functions, we can use them to generate other types of data, e.g. Poisson data via the log link:
```{r}
lambda = exp(-2 + 0.4 * x)
y = rpois(N, lambda)
y
```

- The rate ($\lambda$) of the Poisson distribution has to be positive, so taking the log of it changes its range to $(-\infty,\infty)$ as before. The inverse-link ($\exp$) turns the unrestricted ranges into something that must be positive

## From LM to GLM

- In general, a _generalised linear model_ (GLM) can be written out as:
$$y \sim Distribution(f(\theta, x))$$
where $Distribution$ is some probability distribution, $\theta$ are some parameters, and $f$ is a link function that transforms the parameters into a range so that we can incorporate $x$ in an unrestricted way

- The above allows us to simulate from the model, given some parameters $\theta$ and some covariates $x$ we can use the probability distribution to get simulated data
- It also allows us to calculate the _likelihood_ as we can get a score for how likely it is to see the data we have observed given some values of the parameters

## Multiple covariates

- We can extend LMs and GLMs to have multiple covariates if we want, e.g.
```{r, eval=FALSE}
y = rnorm(N, mean = -2 + 0.4 * x1 - 0.3 * x2, sd = 1)
p = inv.logit(-2 + 0.4 * x1 - 0.3 * x2)
y = rbinom(N, size = 1, prob = p)
```

- Alternatively we can incorporate multiplicative interactions...
```{r, eval=FALSE}
y = rnorm(N, mean = -2 + 0.4 * x1 - 0.3 * x2 + 
            0.05 * x1 * x2, sd = 1)
```

- ... or non-linear effects
```{r, eval=FALSE}
p = inv.logit(-2 + 0.4 * x1 - 0.3 * x2 - 0.02 * x1^2)
y = rbinom(N, size = 1, prob = p)
```

## Directed Acyclic Graphs

- Once we have decided on a model, it is often a good idea to draw a picture of it to make it clear how it works
- In Bayesian statistics, this is commonly done using a Directed Acyclic Graph or DAG which tells us how to simulate from the model. Circles indicate parameters, squares data, and the dotted lines indicate loops
- Here is a DAG for the logistic regression model with two covariates:

\begin{center}
\includegraphics[width=4cm]{DAG.pdf}
\end{center}

## Example: earnings data

- Going back to the earnings data, suppose we want to fit a model to predict log earnings based on sex and whether respondent is white (`eth==3`) or not
- The model is:
$$\log(\mbox{earnings}) \sim N(\alpha + \beta_1 \mbox{height} + \beta_2 \mbox{white}, \sigma^2)$$
- We want to get the posterior distribution of $\alpha, \beta_1, \beta_2$ and $\sigma$ given the data
- What prior distributions could we set on these parameters?

## Fitting linear regression models in rstanarm

Model code:
\tiny
```{r, message=FALSE, warning=FALSE, results='hide'}
earnings = read.csv('../data/earnings.csv')
earnings$white = as.integer(earnings$eth == 3)
mod_1 = stan_lm(y ~ x_centered + white, data = earnings,
                prior = R2(location = 0.5, 'mean'))
```
```{r}
round(as.data.frame(summary(mod_1)), 2)
```

## Plot the posterior values

```{r, fig.height = 6}
plot(mod_1)
```

## Using other priors

\tiny
```{r, message = FALSE, warning = FALSE, results = 'hide'}
mod_2 = stan_lm(y ~ x_centered + white, data = earnings,
                prior = R2(location = 0.5, 'mean'),
                prior_intercept = normal(0, 10))
```
```{r}
round(as.data.frame(summary(mod_2)), 2)
```


## What do the results actually mean?

- We now have access to the posterior distribution of the parameters:

```{r}
post = as.data.frame(mod_2)
head(post)
```

## Plots of output

```{r, fig.height = 6, message=FALSE}
library(bayesplot)
mcmc_areas(post,
           pars = c("x_centered", "white", "sigma"))

```


## `rstan` version

```{r}
stan_code = '
data {
  int<lower=0> N;
  vector[N] y;
  vector[N] x1;
  vector[N] x2;
}
parameters {
  real alpha;
  real beta1;
  real beta2;
  real<lower=0> sigma;
}
model {
  y ~ normal(alpha + x1 * beta1  + x2 * beta2, sigma);
}
'
```

## Running the Stan version

```{r, fig.height = 5, message=FALSE, results='hide'}
library(rstan)
stan_run = stan(data = list(N = nrow(earnings), 
                            y = earnings$y,
                            x1 = earnings$x, 
                            x2 = earnings$white),
                model_code = stan_code)
```

## Stan output

```{r, message=FALSE}
plot(stan_run)
```

## To standardise or not?

- Most regression models work better if the covariates are standardised (subtract the mean and divide by the standard deviation) before you run the model
- `rstan` can struggle with regression models where the data are not standardised. `rstanarm` does a much better job
- The advantage of standardising is that you get more numerically stable results (this is true of `R`'s `lm` function too), and that you can directly compare between the different slopes
- The disadvantage is that the slope values are no longer in the original units (e.g. cm)

## What is stan doing in the background?

- Stans run a stochastic algorithm called Hamiltonian Monte Carlo to create the samples from the posterior distribution
- This involves:

    1. Guessing at _initial values_ of the parameters. Scoring these against the likelihood and the prior to see how well they match the data
    1. Then iterating:
        1. Working out which _directions_ to try to generate new good parameter values
        1. Sampling _new parameter values_ which may or may not be similar to the previous values
        1. Repeating these steps to build up a posterior sample of parameter values
        
- What you end up with is a set of parameter values for however many iterations you chose. 

## How many iterations?

- Ideally you want a set of posterior parameter samples that are independent across iterations and is of sufficient size that you can get decent estimates of uncertainty
- There are three key parts of the algorithm that affect how good the posterior samples are:

    1. The starting values you chose. If you chose bad starting values, you might need to discard the first few thousand iterations. This is known as the _burn-in_ period
    1. The way you choose your new parameter values. If they are too close to the previous values the MCMC might move too slowly so you might need to _thin_ the samples out by taking e.g. every 5th or 10th iteration
    1. The total number of iterations you choose. Ideally you would take millions but this will make the run time slower
    
`rstanarm` and `rstan` have good default choices for these but for complex models you often need to intervene

## Plotting the iterations

You can plot the iterations for all the parameters with `mcmc_trace`, e.g. 
```{r, fig.height = 4}
mcmc_trace(post, pars = c('white', 'x_centered', 'sigma'),
           facet_args = list(nrow = 3))
```

A good trace plot will show no patterns or runs, and will look like it has a stationary mean and variance

## How many chains?

- Beyond increasing the number of iterations, thinning, and removing a burn-in period, Stan automatically runs _multiple chains_
- This means that they start the algorithm from 3 or 4 different sets of starting values and see if each _chain_ converges to the same posterior distribution
- If the MCMC algorithm has converged then each chain should have the same mean and variance.
- Stan reports the `Rhat` value, which is close to 1 when all the chains match
- It's about the simplest and quickest way to check convergence. If you get `Rhat` values above 1.1, run your MCMC for more iterations

## What else can I do with the output

- We could create _credible intervals_ (Bayesian confidence intervals):

\tiny
```{r, fig.height = 6}
mcmc_intervals(post)
```

## Or histograms 

\tiny
```{r, fig.height = 6}
mcmc_hist(post)
```

## Checking model fit

- How do we know if this model fits the data well or not?
- One way is to simulate from the posterior distribution of the parameters, and subsequently simulate from the likelihood to see if the these data match the real data we observed
- This is known as a _posterior predictive check_ 

## Posterior predictive: the long way

 - The long way of doing this is in R after running the model
 - For each value sampled from the posterior, compute:

```{r, eval = FALSE}
y_sim = rnorm(nrow(earnings), 
              post$`(Intercept)`[1] + 
                post$x_centered[1] * earnings$x_centered + 
                post$white[1] * earnings$white, 
              sd = post$sigma[1])
plot(earnings$y, y_sim)
abline(a = 0, b = 1, col = 'red')
```
If the model is good, these should form a straight line!

## Posterior predictive plot for one iteration

```{r, echo = FALSE}
y_sim = rnorm(nrow(earnings), 
              post$`(Intercept)`[1] + 
                post$x_centered[1] * earnings$x_centered + 
                post$white[1] * earnings$white, 
              sd = post$sigma[1])
plot(earnings$y, y_sim, las = 1)
abline(a = 0, b = 1, col = 'red')
```

## Easier posterior predictive distributions

- The easier way is to use the `posterior_predict` command in `rstanarm`:

\small
```{r, fig.height = 5}
y_rep = posterior_predict(mod_2)
y_rep_mean = apply(y_rep, 2, 'mean')
plot(earnings$y, y_rep_mean)
abline(a = 0, b = 1, col = 'red')
```

## More posterior predictive checks

```{r}
pp_check(mod_2)
```


## `rstanarm` GLMs: Swiss Willow tit data

Recall the Willow tit data:
\tiny
```{r}
swt = read.csv('../data/swt.csv')
head(swt)
```
\normalsize

## Fitting a Binomial-logistic model

- Suppose we want to fit a Binomial-logistic model to the first binary replicate with forest cover as a covariate

- The model is:
$$y_i \sim Bin(1, p_i), logit(p_i) = \alpha + \beta x_i$$

- Note that there is no residual standard deviation parameter here. This is because the variance of the binomial distribution depends only on the number of counts (here 1) and the probability, i.e. $Var(y_i) = p_i (1 - p_i)$

## Fitting the model in `rstanarm`

```{r, message=FALSE, results = 'hide'}
mod_3 = stan_glm(rep.1 ~ forest, 
                 data = swt,
                 family = binomial(link = 'logit'),
                 prior = normal(0, 1),
                 prior_intercept = normal(0, 5))
```

## Looking at the output

```{r, echo = FALSE}
plot(mod_3)
```

## Looking at the output

\tiny
```{r, echo = FALSE}
round(as.data.frame(summary(mod_3)), 2)
```

## Plotting the fits

- It's not as easy to plot a fitted line in a Binomial regression model, but we can plot the probabilities:
\small
```{r, fig.height = 4}
post = as.data.frame(mod_3)
plot(swt$forest, swt$rep.1)
points(swt$forest, 
      inv.logit(mean(post$`(Intercept)`) + 
                  mean(post$forest)*swt$forest ),
      col = 'red')
```

## Checking model assumptions

- Just like the linear regression example, we can create posterior predictive distributions for the binary data from the binomial distribution
- However, it isn't as easy to plot as the regression situation as all the true values are 0 and 1. 
- Instead people often use _classification metrics_ which we do not cover in this course (but can discuss if required)

## Binomial modelling as latent data

- The most common way of using binomial or binary data is using the logit link function
- An alternative way of fitting binomial data is via a cut-off normal distribution:
$$y_i = \left\{ \begin{array}{ll} 1 & \mbox{if}\; z_i \ge0 \\ 0 & \mbox{if}\; z_i<0 \end{array} \right.$$
with
$$z_i \sim N(\alpha + \beta x_i, 1)$$
- This is known as probit regression, with $z_i$ a _latent parameter_

## Poisson models

- Here's some `rstanarm` code for a Poisson model:
```{r, eval = FALSE}
mod_4 = stan_glm(rep.1 ~ forest, 
                 data = swt,
                 family = poisson(link = 'log'),
                 prior = normal(0, 1),
                 prior_intercept = normal(0, 5))
```

## Offsets

- For Poisson data it's quite common for the counts to be dependent on the amount of effort required to collect the data
- If there is a variable that quantifies this amount of effort it should be included in the model, as it will be directly linked to the size of the counts
- These variables are often called an _offset_, and are included in the model likelihood via 
```{r, eval = FALSE}
stan_glm(formula, data, 
         family = poisson(link = 'log'), 
         offset = offset, ...)
```

## Further examples of GLM-type data

- As we go through the course we will talk about different types of models for count data
- The Poisson is a bit restrictive, in that the variance and the mean of the counts should be the same, which is rarely satisfied by data
- We'll extend to over-dispersed and zero-inflated data
- We'll also discuss multivariate models using e.g. the multinomial distribution 

## Summary

- GLMs are very easy to fit in `rstanarm` once you get the hang of link functions and extracting the output
- It takes a bit of care to get the posterior distribution out of the model and to decide what you want to do with that
- There are lots of different types of GLM so pick the one that matches your data best
- Don't forget to check model assumptions via e.g. a posterior predictive check. We'll cover more checks later in the course
